p5 
Basic statistical properties of the Box and Jenkins models
Presentation
In this class we will calculate the expected value and the variance of the ARMA models, proposed by Box and Jenkins and presented in class 4. We will start with a review of the formulas already presented for the simpler models (AR and MA of order 1) and then we'll look at the expressions for the higher-order AR and MA models and for the general ARMA class.

Goals
State the expected value and the variance of autoregressive models of order p, AR(p);
State the expected value and variance of q-order moving average models, MA(q)
State the expected value and variance of ARMA models of orders p and q, ARMA(p,q)
5.1 - AR(1) Model - expected value and variance
In class 3, we calculated the expected value and variance of the AR(1) model. In class 4, the same was done for the MA(1) model. The table summarizes the formulas already obtained in these lessons.

Model Representation E(Yt) V(Yt)
AR(1) without constant
Yt=Ï•1Yt(+Îµt
0
Ïƒ21-Ï•12
AR(1) with constant
Yt=Ï•0+Ï•1Yt(+Îµt
Ï•21Ï•1
Ïƒ21Ï•12
MA(1) without constant
Yt = Îµt-Î¸1ÎµtA(
0
(1+Î¸12)Ïƒ2
MA(1) with constant
Yt = Î¸0+(t-Î¸1Îµt(
Î¸0
(1+Î¸12)Ïƒ2
In this class we present a procedure that allows us to calculate the expected value and the variance for higher order AR models and for the more general class of ARMA models. This procedure is only valid for stationary models, that is, that verify the stationarity conditions presented in class 4. Once the conditions are verified, it is imperative that:

E(Yt) = Î¼, âˆ€ t = 1,2,...,T (constant mean)

V(Yt) = ï³2, âˆ€ t = 1,2,...,T (constant variance)

and apply these conditions to calculate the expected value and variance. In section 4.2 we will apply this method to confirm the results found in class 3, for the AR(1) model.

5.2 - AR(1) Model - Expected Value and Variance
In Chapter 3, we saw that for the AR(1) model without constant:

Y1=Îµ1(assuming Y0=0)Y2=Ï•Y1+Îµ2=Ï•Îµ1+Îµ2Y3=Ï•Y2+Îµ3=Ï•Îµ1+Ï•Îµ2+Îµ3Y4=Ï•Y3+Îµ4=Ï•3Îµ1+Ï•2Îµ2+Ï•Îµ3+Îµ4

The general formula for a generic t instant is:

Yt=âˆ‘i=0t-1Ï•iÎµt-1
Whose expected value is:

âˆ‘i=0t-1Ï•iÎµt-i)=âˆ‘i=0t-1Ï•iE(Îµt-1)=0
since ğ¸(Îµğ‘– )=0, by definition.

The variance of (ğ‘Œt) is (the Îµğ‘– are uncorrelated):

V(Yt)=V(âˆ‘Ï•iÎµt-ii=0t-1) =âˆ‘i=0t-1Ï•2iv(Îµt-i) âˆ‘i=0t-1Ï•2iÏƒ2=Ïƒ2âˆ‘i=0t-1Ï•2i.
Now notice that the terms inside the summation define a geometric progression: Ï†0, Ï†2, Ï†4,, ..., up to Ï†2(t-1), that is, with first term 1 (since Ï†0 = 1) and ratio Ï†2. Remembering now that the sum of the terms of a finite geometric progression with t terms, the first term being equal to "a" _1 and the ratio equal to q, is given by:

St=a1(1-qt)1-q
And noting that, in the case in question, a1 = 1 and q = Ï†2, we have:

âˆ‘Ï•2ii=0t-1 = 1-Ï•2t1-Ï•2

And so:

âˆ‘Ï•2ii=0t-1 = 1-Ï•2t1-Ï•2
Note that if t tends to infinity, the above result is constant since |Ï†| < 1, in which case the term Ï†2t approaches zero. In this case:

V(Yt)= Ï•21-Ï•2
For the model with constant:

Yt=Ï•0+Ï•1Yt-1+Îµt
The expected value was obtained as follows:

Yt=Ï•0âˆ‘i=0t-1Ï•1i+âˆ‘i=0t-1Ï•1iÎµt-1,E(Yt) = Ï•0âˆ‘i=0t-1Ï•1i
As for the sum, we can apply the formula for the sum of the geometric progression:

âˆ‘i=0t-1Ï•1i=1-Ï•1i1-Ï•1.
Applying the obtained expression to the expected value:

E(Yt)=Ï•0âˆ‘i=0t-1Ï•1i=Ï•01-Ï•1t1-Ï•1.
Again, if |Ï†1 | < 1, Ï†t' tends to zero when t tends to infinity, and in this case:

E(Yt)=Ï•01-Ï•1.
And the variance:

V(Yt)=Ïƒ2âˆ‘i=0t-1Ï•2i=1-Ï•2t1-Ï•2Ïƒ2.
Again, if t tends to infinity, the above result is constant since |ï¦| < 1, in which case the term ï¦^2ğ‘¡ approaches zero. In this case:

V(Yt)=Ïƒ21-Ï•2
Next, we will confirm the expected value and variance of AR(1). Confirming the expected value of AR(1) (with constant):

E(Yt)=E(Ï•0 )+Ï•1 E(Yt-1) +EÎµt =Ï•0+Ï•1E(Yt-1) ++0 =Ï•0+Ï•1E(Yt-1).

The problem is that we don't know E(Ytâˆ’1).

However, under" stationarity, we have that E(Yt)=E(Ytâˆ’1).

Hence:E(Yt )=Ï•0+Ï•1E(Yt)â‡’E(Yt) Ï•01-Ï•1, as we wanted to demonstrate.
Comment
Note that the method above is much easier than the recursive method adopted in class 3. Additionally, for that method it becomes unfeasible to extend the results to more complex models. Using the stationarity property, this task becomes simple.

Confirming the variance of AR(1) (with constant):

V(Yt )=V(Ï•0)+Ï•12V(Yt-1 )+V(Îµt)=0+Ï•12V(Yt-1 )+Ïƒ2, since Cov (Yt-1, Îµt)
Again, the problem is that we don't know V(Ytâˆ’1).

However, under" stationarity, we have that:V(Yt ) = V(Ytâˆ’1).

Hence: V(Yt )=Ï•12V(Yt )+Ïƒ2â‡’V(Yt )=Ïƒ21=Ï•12, as we wanted to demonstrate.
To prove"r that " Cov(Ytâˆ’1,Îµt)0, let's use "the general form of AR" (1), already derived in class 3." The general form ad:"

Yt =Ï•0(1+Ï•0+Ï•12+...+Ï•1t...)+Ï•1t+Îµ1+Ï•1tÎµ2+...+Îµt or:

All terms on the right side of this equation have zero correlation with ğœ€_ğ‘¡, as it is white noise. This concludes the test.

 
Next, we will expand the above results to higher order models.

 5.3 - Models AR(2) and AR(p)

 Starting with AR(2), represented by the following equation:

Yt =Ï•0+Ï•1Yt-1 +Ï•2Yt-2 +Îµt
So:

E(Yt )=E(Ï•0)+Ï•1E(Yt-1 )+Ï•2E(Yt-2 )+E(Îµt )=Ï•0+Ï•1E(Yt-1 )+Ï•2E(Yt-2 )+0=Ï•0+Ï•1E (Yt-1 )+Ï•2E(Yt-2)
However, under" stationarity, we have that Yt = E(Yt-1=Yt-2)

Hence: E(Yt )=Ï•0+Ï•1E(Yt )+Ï•2E(Yt )â‡’E(Yt )=Ï•01Ï•1-Ï•2
With analogous accounts, it's easy to see that, in the case of AR(p):

E(Yt )=Ï•01âˆ‘j=1pÏ•j
5.4 - MA(2) and MA(q) models
Recall that the MA(q) model is represented by the following equation:

Yt=Îµt-Î¸1Îµtem-Î¸2Îµtem
As this model is given by a linear combination of current and lagged values â€‹â€‹of a white noise, we have a facilitator, which is precisely the simplifying properties of a white noise stochastic process, presented in class 3 and remembered below:

E(Îµt)=0,âˆ€tV(Îµt)=Ïƒ2,âˆ€tCorr(Îµi,Îµj)=0,âˆ€t, r
Thus, the use of the method proposed in section 4.1 is not even necessary, and it is immediate to generalize the results of the MA(1) model obtained in class 4 to the MA(2) and MA(q) models.

Remembering that in the case of MA(1) we proceeded (in class 4) as follows:

E(Yt)=0 (without added constant) or Î¸0(with constant Î¸0).V(Yt)=V(Îµt)+Î¸12V(Îµtvc), because Cov(Îµt,Îµt,o)=0.E as V( Îµt)=V(Îµtvc)=Ïƒ2, we arrive at:V(Yt)=Ïƒ2+Î¸12Ïƒ2=(1+Î¸12)Ïƒ2
Thus:

V(Yt)=Ïƒ2+Î¸12Ïƒ2+Î¸22Ïƒ2=(1+Î¸12+Î¸212)Ïƒ2

It is easy to generalize the above formula to the MA(q) model:

V(Yt)=(1+âˆ‘j=1qÎ¸12)Ïƒ2
The presence of a constant Î¸0 does not change the results for the variance in any way.

Consider the following MA(2) model:

Yt=Îµt-0.6Îµt-1-0.3Îµt-2, Îµt ~i.i.dN(0, 2), âˆ€t
Determine the expected value and variance of this model.

E(Yt )=0 (since there is no added constant)V(Yt)=(1+Î¸12+Î¸22)Ïƒ2=(1+(0.6)2+(0.3)2 ) 221.45âˆ—4 = 5.8."
5.5 - ARMA model(1,1)
The ARMA(1,1) equation is recalled below:

Yt =Ï•1Yte +Îµt+1Îµte
Following the logic of what has already been done for the case of the AR(1) model, remembering that E(Îµt )=0, âˆ€t, it is easily shown that:

E(Yt)=Ï•01-Ï•1,
a result that would also be valid for an ARMA(1,q), q > 1.

As for an ARMA(p,q), it can be shown very simply that:

E(Yt)=Ï•01=âˆ‘j=1pÏ•j,
The calculation of the variance of the ARMA(1,1) model involves a more complex algebrism, shown below.

First, to calculate V(Ï•1 Yt-1+ ğœ€t + ğœƒ1ğœ€ğ‘¡âˆ’1, one must take into account that ğ‘Œğ‘¡âˆ’1 and ğœ€ğ‘¡âˆ’1 are correlated, and so the following result of probability theory will be useful:

Let C = aX + bY, a linear combination of two random variables X and Y, where a and b are constant. So, it can be proved that:

V(C) = a2V(X) + b2V(Y) + 2abCov(X,Y).

First, it is verified that neither ğ‘Œğ‘¡âˆ’1 nor ğœ€ğ‘¡âˆ’1 present correlates ğœ€_ğ‘¡. Thus:

V(Ï•1Yt(s+Îµt+(1Îµt(s) =V(Ï•1Yt(s+(1Îµt(s)) +V(Îµt)
Now, to calculate V(Ï•1Ytgo+g1Îµtgo), it is necessary to apply the formula of V(C), using X=Ytn, Y=ÎµtY, a=â–¡Ï•1 and b=e1. We will have as a result:

V(Ï•1Yt(T+(1Îµt(T)=Ï†12V(Yt=T)Î¸12V(Îµt=T)-=Ï†1Î¸1Cov(Ytov, Îµtov)
Remembering now that V(Îµt)=Ïƒ2, âˆ€t, we have:

V(Yt)=Ï†12V(Ytt)+Î¸12Ïƒ2-Ï†1Î¸1Cov(Ytov, Îµtov)+Ïƒ2
Remembering now that Cov(Ytov,Îµtov) is presented next.

V(Yt)=Ï†12V(Ytt)+Î¸12Ïƒ2-Ï†1Î¸1Cov(Ytov, Îµtov)+Ïƒ2Cov(Ytov, Îµtov)=Cov(Ï†1Ytov +Îµtov-Î¸1Îµtov,Îµtov)=Cov(Îµtov,Îµtov)=V(ÎµtVav)= (Yt)=Ï†12V(Ytt)+V(Îµt)+Î¸12V(Îµt(v)VÏ†1Î¸1Ïƒ2
Finally, under" stationarity, we have: V(Yt)=V(YtVs)

So:

V(Yt)=Ï†12V(Yt)+Ïƒ2+Î¸12Ïƒ2-sÏ†1Î¸1Ïƒ2(1si12) V (Yt)+Ïƒ2+Î¸12Ïƒ2-VÏ†1Î¸1Ïƒ2â‡’V(Yt)=1+Î¸12-+Ï†1Î¸11+Ï†12Ïƒ2
A common â€œgotchaâ€ in public tenders is usually the presentation of the above formula without considering the covariance term in the demonstration, which would result in:

V(Yt)=1+Î¸121+Ï†12Ïƒ2
Finally, note that a constant added to the model would not change its variance.

Let's see an example? Consider the following ARMA(1,1) model:

Yt=0.2 +0.5Yt5+ Îµt+-0.8Îµt0,Îµt ~iidN(0, 3), âˆ€tDetermine the expected value and variance of this model.Solution:E(Yt)=Ï•01-Ï•1=0.20.5=0.4V( Yt)=1+(-+0.)2-+(0.5)(-.5.)1.Ï†124=2,440.754=â‰…13.
We are now able to expand the framework at the beginning of the class to incorporate the new results:
The calculation of the variance of these models involves algebra, which is beyond the scope of this material and will be left as an extension.

Example 5.3 - Look at the series below. Which one or which of the models on the board could you discard to represent it?

The model mean Yt=3 +0.5Yt-1+ Îµt where Îµt ~i.i.dN(0, 1), âˆ€t, is:

a) 0
b) 1.5
c) 3
d) 6
e) 8


Option d. 3/(1-0.5) = 3/0.5 = 6.

The variance of the model Yt=3 + Îµt- 0.5Îµt-1 where Îµt ~i.i.dN(0, 4), âˆ€t, is:

a) 3
b) 5
c) 8
d) 6
e) 12


Option b. (1+0.52)*4 = 1.25*4 = 5.

The following is the annual series of bituminous coal production in the United States between the years 1920 and 1968.

Source: HYNDMAN, R.J.; ATHANASOPOULOS (2018)

Which of the following models would be a candidate to represent this series?

a) Simple random walk
b) Random walk with constant
c) AR(1) stationary without constant
d) AR(1) stationary with constant
e) None of the above


Option d. It is the only one among the options that characterizes a stationary model in the mean and with a mean different from zero.


